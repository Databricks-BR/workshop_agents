{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef0d3e84-c79a-4e71-9712-d8fe89a27e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://raw.githubusercontent.com/Databricks-BR/workshop_agents/refs/heads/main/demo-main/img/header_workshop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c331f751-9bec-42b9-9760-22625e3679bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    " Item | Description |\n",
    " --- | --- |\n",
    " **Objective** | Create Vector Search Index and Endpoint |\n",
    " **Databricks Run Time** | DBR 16.4 LTS |\n",
    " **Language** | Python, Pyspark and SQL |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "512124bf-5313-4846-bd49-6a43a5dd2f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://raw.githubusercontent.com/Databricks-BR/workshop_agents/refs/heads/main/demo-main/img/img/04_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3aa4d60-30e6-4e1c-bf22-1f6bc245af12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Querying Unstructured Data\n",
    ".\n",
    "<img src=\"https://www.databricks.com/sites/default/files/2024-01/db-vector-search-image-01_0.png?v=1705100714\" style=\"width: 800px; margin-left: 10px\">\n",
    "\n",
    "However, often the data we need to access is not necessarily structured or we are not looking for an exact search.\n",
    "\n",
    "**Databricks Vector Search** is a serverless vector database, **integrated** seamlessly into the Data Intelligence Platform.\n",
    "\n",
    "Unlike other databases, Databricks Vector Search supports **automatic synchronization** of data from the source to the index, eliminating the complex and costly maintenance of pipelines.\n",
    "\n",
    "It leverages the same **security and governance** tools that organizations have already built for greater peace of mind.\n",
    "\n",
    "With its serverless design, Databricks Vector Search **scales** easily to support billions of embeddings and thousands of real-time queries per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea77495-785a-4e62-ae5c-420bb639e75a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2aada0f-2db4-4b2d-8b8f-07ac622cc6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook: Parse PDF using Python and Save to Delta\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 0: Installs and Imports\n",
    "# ==============================================================================\n",
    "# This notebook reads a PDF, extracts question and answer pairs using a robust\n",
    "# Python-based parser, and saves the result as a Delta Table.\n",
    "# This method works on any Databricks cluster.\n",
    "\n",
    "%pip install pypdf --quiet\n",
    "\n",
    "dbutils.library.restartPython()\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 1: Configuration\n",
    "# ==============================================================================\n",
    "# Please fill in these variables with your own Unity Catalog names.\n",
    "CATALOG = \"vinicius_fialho_testes\"\n",
    "SCHEMA = \"workshop_ml_agentes\"\n",
    "VOLUME = \"unstructured_data\"\n",
    "PDF_FILE_NAME = \"faq-meli-ir.pdf\"\n",
    "DELTA_TABLE_NAME = \"faq\"\n",
    "\n",
    "# --- Construct full paths ---\n",
    "PDF_PATH = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/{PDF_FILE_NAME}\"\n",
    "DELTA_TABLE_FQN = f\"{CATALOG}.{SCHEMA}.{DELTA_TABLE_NAME}\"\n",
    "\n",
    "print(f\"Reading PDF from: {PDF_PATH}\")\n",
    "print(f\"Will create Delta Table at: {DELTA_TABLE_FQN}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Extract Questions and Answers from the PDF\n",
    "# ==============================================================================\n",
    "# This is the most reliable method using Python's regex library.\n",
    "\n",
    "def extract_qa_pairs_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF and splits it into (question, answer) pairs\n",
    "    based on the FAQ structure (Question in ALL CAPS ending with '?' followed by the answer).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pypdf import PdfReader\n",
    "        reader = PdfReader(pdf_path)\n",
    "        # Add newlines for better regex matching at the start/end of the document\n",
    "        raw_text = \"\\n\" + \"\".join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "        # This pattern finds multi-line, all-caps questions ending in '?'.\n",
    "        # We will use finditer to get the exact start and end positions of each question.\n",
    "        question_pattern = r'(\\n[A-Z][A-Z\\s,]+\\?\\n)'\n",
    "        matches = list(re.finditer(question_pattern, raw_text))\n",
    "\n",
    "        if not matches:\n",
    "            print(\"Warning: Regex did not find any matching Q&A patterns. The PDF structure might be different than expected.\")\n",
    "            return []\n",
    "\n",
    "        # --- Stage 1: Initial rough extraction ---\n",
    "        qa_pairs = []\n",
    "        for i, match in enumerate(matches):\n",
    "            question_text = match.group(1)\n",
    "            answer_start_pos = match.end()\n",
    "            answer_end_pos = matches[i+1].start() if i + 1 < len(matches) else len(raw_text)\n",
    "            answer_text = raw_text[answer_start_pos:answer_end_pos]\n",
    "            qa_pairs.append([ # Use a list to make it mutable\n",
    "                \" \".join(question_text.strip().split()),\n",
    "                \" \".join(answer_text.strip().split())\n",
    "            ])\n",
    "        \n",
    "        # --- Stage 2: Cleanup process to fix question fragments in answers ---\n",
    "        # We iterate backwards to safely modify the next item in the list.\n",
    "        for i in range(len(qa_pairs) - 2, -1, -1):\n",
    "            current_answer = qa_pairs[i][1]\n",
    "            \n",
    "            # This pattern implements your rule: a period, a space, and then at least 3 ALL CAPS words.\n",
    "            # This indicates the start of a question fragment.\n",
    "            spillover_pattern = r'\\. (?=([A-Z\\']{2,}\\s){2,}[A-Z\\']{2,})'\n",
    "            match = re.search(spillover_pattern, current_answer)\n",
    "            \n",
    "            if match:\n",
    "                split_point = match.start()\n",
    "                \n",
    "                # The text that belongs to the next question\n",
    "                spillover_text = current_answer[split_point+2:].strip()\n",
    "                \n",
    "                # The corrected answer for the current question\n",
    "                corrected_answer = current_answer[:split_point+1].strip()\n",
    "                \n",
    "                # Update the current answer\n",
    "                qa_pairs[i][1] = corrected_answer\n",
    "                \n",
    "                # Prepend the fragment to the next question\n",
    "                qa_pairs[i+1][0] = f\"{spillover_text} {qa_pairs[i+1][0]}\"\n",
    "\n",
    "        # Convert list of lists back to list of tuples for the final output\n",
    "        final_pairs = [tuple(pair) for pair in qa_pairs if pair[0] and pair[1]]\n",
    "\n",
    "        print(f\"Successfully extracted and cleaned {len(final_pairs)} Question/Answer pairs.\")\n",
    "        return final_pairs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or processing PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "qa_pairs = extract_qa_pairs_from_pdf(PDF_PATH)\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Create and Save the Delta Table\n",
    "# ==============================================================================\n",
    "# This section creates the table with id, pergunta, and resposta columns.\n",
    "\n",
    "def create_qa_delta_table(qa_data, table_fqn):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame with the Q&A data and saves it as a Delta Table.\n",
    "    \"\"\"\n",
    "    if not qa_data:\n",
    "        print(\"No data to process. Halting execution.\")\n",
    "        return\n",
    "    \n",
    "    # Creates a pandas DataFrame with temporary english column names.\n",
    "    df_pandas = pd.DataFrame(qa_data, columns=['question', 'answer'])\n",
    "    \n",
    "    # Adds a sequential 'id' column.\n",
    "    df_pandas.reset_index(inplace=True)\n",
    "    \n",
    "    # Renames columns to the desired Portuguese names.\n",
    "    df_pandas = df_pandas.rename(columns={'index': 'id', 'question': 'question', 'answer': 'answer'})\n",
    "    \n",
    "    # Creates a Spark DataFrame and saves it.\n",
    "    spark_df = spark.createDataFrame(df_pandas)\n",
    "    print(f\"\\nWriting to Delta Table: {table_fqn}...\")\n",
    "    spark_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(table_fqn)\n",
    "    print(\"=\"*80)\n",
    "    print(\"SUCCESS! Your Delta Table with questions and answers is ready.\")\n",
    "    print(\"=\"*80)\n",
    "    display(spark.table(table_fqn).limit(5))\n",
    "\n",
    "# Run the final function\n",
    "create_qa_delta_table(qa_pairs, DELTA_TABLE_FQN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "859c9d13-9e21-4dea-8a48-b399e3293169",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757342408640}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM vinicius_fialho_testes.workshop_ml_agentes.faq\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc6758ce-4507-4e06-a663-031e157d48fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Enable Change Data Feed on the `FAQ` table\n",
    "-- This configuration allows Vector Search to read inserted, deleted, or updated data in the FAQ incrementally.\n",
    "\n",
    "ALTER TABLE vinicius_fialho_testes.workshop_ml_agentes.faq SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62b4399c-97ae-44cc-86d7-e600c85ceb9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Creating Vector Search Index and Endpoint via UI.\n",
    "\n",
    "[Our Vector Search Endpoint](https://e2-demo-field-eng.cloud.databricks.com/explore/data/vinicius_fialho_testes/workshop_ml_agentes/faq_vs?o=1444828305810485&activeTab=overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c889986-a013-44c1-b6c8-52de3cc6b044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](/Workspace/Users/vinicius.fialho@databricks.com/Hunter/mercado_libre/workshop_01/img/04_VS Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "babb0058-4b0c-446d-ac0d-0f89ec3f6a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Consulting a FAQ\n",
    "\n",
    "Knowledge bases, such as FAQs, service scripts, and compliance rules, can be easily indexed with Databricks Vector Search. With this, we can:\n",
    "\n",
    "* Identify relevant documents\n",
    "* Increase the accuracy of responses from Generative AI models\n",
    "* No need to pre-train or fine-tune these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e08f3162-a642-4f9b-9819-85e3d62548a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION vinicius_fialho_testes.workshop_ml_agentes.search_faq(question STRING)\n",
    "RETURNS TABLE(id LONG, question STRING, answer STRING)\n",
    "COMMENT 'Use this function to query the knowledge base about delivery times, exchange or return requests, among other frequently asked questions about our marketplace'\n",
    "RETURN select id, question, answer from vector_search(\n",
    "  index => 'vinicius_fialho_testes.workshop_ml_agentes.faq_vs', \n",
    "  query => search_faq.question,\n",
    "  num_results => 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0c50ac-98b7-4e91-9ca0-c62847110b75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM vinicius_fialho_testes.workshop_ml_agentes.search_faq(\"Does Meli generate revenue from logistics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1fbcbb3-2c28-4b19-b264-5868fcf19df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM vinicius_fialho_testes.workshop_ml_agentes.search_faq(\"Â¿Donde se muestran los anuncios de Mercado Libre?\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7371972696243803,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "04_create_vector_search",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
