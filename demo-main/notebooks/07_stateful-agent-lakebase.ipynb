{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe76e35d-5cb3-4df2-b6e6-b77d22a32b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a Stateful Agent with Thread-scoped memory using Databricks Lakebase and LangGraph\n",
    "This notebook demonstrates how to build a stateful agent using the Mosaic AI Agent Framework and LangGraph, with Lakebase as the agent’s durable memory and checkpoint store. Threads allow you to store conversational state in Lakebase so you can pass in thread IDs into your agent instead of needing to send the full conversation history.\n",
    "In this notebook, you will:\n",
    "1. Author a Stateful Agent graph with Lakebase (the new Postgres database in Databricks) and Langgraph to manage state using thread ids in a Databricks Agent \n",
    "2. Wrap the LangGraph agent with `ResponsesAgent` interface to ensure compatibility with Databricks features\n",
    "3. Test the agent's behavior locally\n",
    "4. Register model to Unity Catalog, log and deploy the agent for use in apps and Playground\n",
    "\n",
    "We are using [PostgresSaver in Langgraph](https://api.python.langchain.com/en/latest/checkpoint/langchain_postgres.checkpoint.PostgresSaver.html) to open a connection with our Lakebase Postgres database.\n",
    "\n",
    "## Why use Lakebase?\n",
    "Stateful agents need a place to persist, resume, and inspect their work. Lakebase provides a managed, UC-governed store for agent state:\n",
    "- Durable, resumable state. Automatically capture threads, intermediate checkpoints, tool outputs, and node state after each graph step so you can resume, branch, or replay any point in time.\n",
    "- Queryable & observable. Because state lands in the Lakehouse, you can use SQL (or notebooks) to audit conversations and build upon other Databricks functionality like dashboards\n",
    "- Governed by Unity Catalog. Apply data permissions, lineage, and auditing to AI state, just like any other table.\n",
    "\n",
    "## What are Stateful Agents?\n",
    "Unlike stateless LLM calls, a stateful agent keeps and reuses context across steps and sessions. Each new conversation is tracked with a thread ID, which represents the logical task or dialogue stream. Pick up an existing thread at any time to continue the conversation without having to pass in the entire conversation history.\n",
    "\n",
    "## Prerequisites\n",
    "- Create a Lakebase instance, see Databricks documentation ([AWS](https://docs.databricks.com/aws/en/oltp/create/) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/oltp/create/)). \n",
    "- You can create a Lakebase instance by going to SQL Warehouses -> Lakebase Postgres -> Create database instance. You will need to retrieve values from the \"Connection details\" section of your Lakebase to fill out this notebook.\n",
    "- Complete all the \"TODO\"s throughout this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76004990-0c77-4b94-8043-2600a898cec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f22883-abd7-49b2-a937-e5d3fdc7549f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "or"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq databricks-langchain langgraph==0.5.3 uv databricks-agents mlflow-skinny[databricks] \\\n",
    "  langgraph-checkpoint-postgres==2.0.21 psycopg[binary,pool]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c38150d3-7871-4cc1-9538-72ce61a1e992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## First time setup only: Set up checkpointer with your Lakebase instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10d270f1-ce5a-42ca-b1cf-7e60f56212e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from psycopg_pool import ConnectionPool\n",
    "import psycopg\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "# TODO: Fill in your lakebase instance details here. For the username, create a\n",
    "# Service Principal and grant it databricks_superuser permissions onto the lakebase instance.\n",
    "# See Service Principal Documentation for more information:\n",
    "# https://docs.databricks.com/en/admin/users-groups/service-principals\n",
    "# Use the Service Principal client id and secret as the SP_CLIENT_ID/SP_CLIENT_SECRET\n",
    "# This will help initialize the checkpointers\n",
    "DB_INSTANCE_NAME = \"lakebase-erico-silva\"  \n",
    "DB_NAME          = \"databricks_postgres\"\n",
    "SP_CLIENT_ID      = os.getenv(\"DATABRICKS_CLIENT_ID\")\n",
    "SP_CLIENT_SECRET      = os.getenv(\"DATABRICKS_CLIENT_SECRET\")\n",
    "SSL_MODE         = \"require\"\n",
    "DB_HOST = \"instance-9c1487ee-b26a-45c9-8ef1-55d6e9dd531b.database.cloud.databricks.com\"\n",
    "DB_PORT = 5432\n",
    "WORKSPACE_HOST = \"https://e2-demo-field-eng.cloud.databricks.com\"\n",
    "\n",
    "w = WorkspaceClient(\n",
    "  host = WORKSPACE_HOST,\n",
    "  client_id = SP_CLIENT_ID,\n",
    "  client_secret = SP_CLIENT_SECRET\n",
    ")\n",
    "\n",
    "def db_password_provider() -> str:\n",
    "    \"\"\"\n",
    "    Ask Databricks to mint a fresh DB credential for this instance.\n",
    "    \"\"\"\n",
    "    cred = w.database.generate_database_credential(\n",
    "        request_id=str(uuid.uuid4()),\n",
    "        instance_names=[DB_INSTANCE_NAME],\n",
    "    )\n",
    "    return cred.token\n",
    "\n",
    "class CustomConnection(psycopg.Connection):\n",
    "    \"\"\"\n",
    "    A psycopg Connection subclass that injects a fresh password\n",
    "    *at connection time* (only when the pool creates a new connection).\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def connect(cls, conninfo=\"\", **kwargs):\n",
    "        # Append the new password to kwargs\n",
    "        kwargs[\"password\"] = db_password_provider()\n",
    "        # Call the superclass's connect method with updated kwargs\n",
    "        return super().connect(conninfo, **kwargs)\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    conninfo=f\"dbname={DB_NAME} user={SP_CLIENT_ID} host={DB_HOST} port={DB_PORT} sslmode={SSL_MODE}\",\n",
    "    connection_class=CustomConnection,\n",
    "    min_size=1,\n",
    "    max_size=10,\n",
    "    open=True,\n",
    ")\n",
    "\n",
    "# Use the pool to initialize your checkpoint tables\n",
    "with pool.connection() as conn:\n",
    "    conn.autocommit = True   # disable transaction wrapping\n",
    "    checkpointer = PostgresSaver(conn)\n",
    "    checkpointer.setup()\n",
    "    conn.autocommit = False  # restore default if you want transactions later\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select 1\")\n",
    "    print(\"✅ Pool connected and checkpoint tables are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62543b14-2596-4cae-8dda-25735513c037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the agent in code\n",
    "\n",
    "## Write agent code to file agent.py\n",
    "Define the agent code in a single cell below. This lets you write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n",
    "\n",
    "## Wrap the LangGraph agent using the ResponsesAgent interface\n",
    "For compatibility with Databricks AI features, the `LangGraphResponsesAgent` class implements the `ResponsesAgent` interface to wrap the LangGraph agent.\n",
    "\n",
    "Databricks recommends using `ResponsesAgent` as it simplifies authoring multi-turn conversational agents using an open source standard. See MLflow's [ResponsesAgent documentation](https://www.mlflow.org/docs/latest/llms/responses-agent-intro/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c3edf07-485c-4338-b3ea-bf69262b0cd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import urllib.parse\n",
    "import uuid\n",
    "from threading import Lock\n",
    "from typing import Annotated, Any, Generator, Optional, Sequence, TypedDict\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "import psycopg\n",
    "from psycopg_pool import ConnectionPool\n",
    "from psycopg.rows import dict_row\n",
    "from contextlib import contextmanager\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=os.getenv(\"LOG_LEVEL\", \"INFO\"))\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "# TODO: Update with your system prompt\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant. Use the available tools to answer questions.\"\n",
    "\n",
    "# TODO: Fill in Lakebase config values here\n",
    "LAKEBASE_CONFIG = {\n",
    "    \"instance_name\": \"lakebase-erico-silva\",\n",
    "    \"conn_host\": \"instance-9c1487ee-b26a-45c9-8ef1-55d6e9dd531b.database.cloud.databricks.com\",\n",
    "    \"conn_db_name\": \"databricks_postgres\",\n",
    "    \"conn_ssl_mode\": \"require\",\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent,enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/en/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "\n",
    "tools = []\n",
    "\n",
    "# Example UC tools; add your own as needed\n",
    "UC_TOOL_NAMES: list[str] = []\n",
    "if UC_TOOL_NAMES:\n",
    "    uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES)\n",
    "    tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# Use Databricks vector search indexes as tools\n",
    "# See https://docs.databricks.com/en/generative-ai/agent-framework/unstructured-retrieval-tools.html#locally-develop-vector-search-retriever-tools-with-ai-bridge\n",
    "# List to store vector search tool instances for unstructured retrieval.\n",
    "VECTOR_SEARCH_TOOLS = []\n",
    "\n",
    "# To add vector search retriever tools,\n",
    "# use VectorSearchRetrieverTool and create_tool_info,\n",
    "# then append the result to TOOL_INFOS.\n",
    "# Example:\n",
    "# VECTOR_SEARCH_TOOLS.append(\n",
    "#     VectorSearchRetrieverTool(\n",
    "#         index_name=\"\",\n",
    "#         # filters=\"...\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "tools.extend(VECTOR_SEARCH_TOOLS)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "\n",
    "class CredentialConnection(psycopg.Connection):\n",
    "    \"\"\"Custom connection class that generates fresh OAuth tokens with caching.\"\"\"\n",
    "    \n",
    "    workspace_client = None\n",
    "    instance_name = None\n",
    "    \n",
    "    # Cache attributes\n",
    "    _cached_credential = None\n",
    "    _cache_timestamp = None\n",
    "    _cache_duration = 3000  # 50 minutes in seconds (50 * 60)\n",
    "    _cache_lock = Lock()\n",
    "    \n",
    "    @classmethod\n",
    "    def connect(cls, conninfo='', **kwargs):\n",
    "        \"\"\"Override connect to inject OAuth token with 50-minute caching\"\"\"\n",
    "        if cls.workspace_client is None or cls.instance_name is None:\n",
    "            raise ValueError(\"workspace_client and instance_name must be set on CredentialConnection class\")\n",
    "        \n",
    "        # Get cached or fresh credential and append the new password to kwargs\n",
    "        credential_token = cls._get_cached_credential()\n",
    "        kwargs['password'] = credential_token\n",
    "        \n",
    "        # Call the superclass's connect method with updated kwargs\n",
    "        return super().connect(conninfo, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_cached_credential(cls):\n",
    "        \"\"\"Get credential from cache or generate a new one if cache is expired\"\"\"\n",
    "        with cls._cache_lock:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # Check if we have a valid cached credential\n",
    "            if (cls._cached_credential is not None and \n",
    "                cls._cache_timestamp is not None and \n",
    "                current_time - cls._cache_timestamp < cls._cache_duration):\n",
    "                return cls._cached_credential\n",
    "            \n",
    "            # Generate new credential\n",
    "            credential = cls.workspace_client.database.generate_database_credential(\n",
    "                request_id=str(uuid.uuid4()),\n",
    "                instance_names=[cls.instance_name]\n",
    "            )\n",
    "            \n",
    "            # Cache the new credential\n",
    "            cls._cached_credential = credential.token\n",
    "            cls._cache_timestamp = current_time\n",
    "            \n",
    "            return cls._cached_credential\n",
    "\n",
    "\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"Stateful agent using ResponsesAgent with Lakebase PostgreSQL checkpointing.\n",
    "    \n",
    "    Features:\n",
    "    - Connection pooling with credential rotation and caching\n",
    "    - Thread-based conversation state persistence\n",
    "    - Tool support with UC functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lakebase_config: dict[str, Any]):\n",
    "        self.lakebase_config = lakebase_config\n",
    "        self.workspace_client = WorkspaceClient()\n",
    "        \n",
    "        # Model and tools\n",
    "        self.model = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "        self.system_prompt = SYSTEM_PROMPT\n",
    "        self.model_with_tools = self.model.bind_tools(tools) if tools else self.model\n",
    "        \n",
    "        # Connection pool configuration\n",
    "        self.pool_min_size = int(os.getenv(\"DB_POOL_MIN_SIZE\", \"1\"))\n",
    "        self.pool_max_size = int(os.getenv(\"DB_POOL_MAX_SIZE\", \"10\"))\n",
    "        self.pool_timeout = float(os.getenv(\"DB_POOL_TIMEOUT\", \"30.0\"))\n",
    "        \n",
    "        # Token cache duration (in minutes, can be overridden via env var)\n",
    "        cache_duration_minutes = int(os.getenv(\"DB_TOKEN_CACHE_MINUTES\", \"50\"))\n",
    "        CredentialConnection._cache_duration = cache_duration_minutes * 60\n",
    "        \n",
    "        # Initialize the connection pool with rotating credentials\n",
    "        self._connection_pool = self._create_rotating_pool()\n",
    "        \n",
    "        mlflow.langchain.autolog()\n",
    "\n",
    "    def _get_username(self) -> str:\n",
    "        \"\"\"Get the username for database connection\"\"\"\n",
    "        try:\n",
    "            sp = self.workspace_client.current_service_principal.me()\n",
    "            return sp.application_id\n",
    "        except Exception:\n",
    "            user = self.workspace_client.current_user.me()\n",
    "            return user.user_name\n",
    "\n",
    "    def _create_rotating_pool(self) -> ConnectionPool:\n",
    "        \"\"\"Create a connection pool that automatically rotates credentials with caching\"\"\"\n",
    "        # Set the workspace client and instance name on the custom connection class\n",
    "        CredentialConnection.workspace_client = self.workspace_client\n",
    "        CredentialConnection.instance_name = self.lakebase_config[\"instance_name\"]\n",
    "        \n",
    "        username = self._get_username()\n",
    "        host = self.lakebase_config[\"conn_host\"]\n",
    "        database = self.lakebase_config.get(\"conn_db_name\", \"databricks_postgres\")\n",
    "        \n",
    "        # Create pool with custom connection class\n",
    "        pool = ConnectionPool(\n",
    "            conninfo=f\"dbname={database} user={username} host={host} sslmode=require\",\n",
    "            connection_class=CredentialConnection,\n",
    "            min_size=self.pool_min_size,\n",
    "            max_size=self.pool_max_size,\n",
    "            timeout=self.pool_timeout,\n",
    "            open=True,\n",
    "            kwargs={\n",
    "                \"autocommit\": True, # Required for the .setup() method to properly commit the checkpoint tables to the database\n",
    "                \"row_factory\": dict_row, # Required because the PostgresSaver implementation accesses database rows using dictionary-style syntax\n",
    "                \"keepalives\": 1,\n",
    "                \"keepalives_idle\": 30,\n",
    "                \"keepalives_interval\": 10,\n",
    "                \"keepalives_count\": 5,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Test the pool\n",
    "        try:\n",
    "            with pool.connection() as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute(\"SELECT 1\")\n",
    "            logger.info(\n",
    "                f\"Connection pool with rotating credentials created successfully \"\n",
    "                f\"(min={self.pool_min_size}, max={self.pool_max_size}, \"\n",
    "                f\"token_cache={CredentialConnection._cache_duration / 60:.0f} minutes)\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            pool.close()\n",
    "            raise ConnectionError(f\"Failed to create connection pool: {e}\")\n",
    "        \n",
    "        return pool\n",
    "    \n",
    "    @contextmanager\n",
    "    def get_connection(self):\n",
    "        \"\"\"Context manager to get a connection from the pool\"\"\"\n",
    "        with self._connection_pool.connection() as conn:\n",
    "            yield conn\n",
    "    \n",
    "    def _langchain_to_responses(self, messages: list[BaseMessage]) -> list[dict[str, Any]]:\n",
    "        \"\"\"Convert from LangChain messages to Responses API format\"\"\"\n",
    "        responses = []\n",
    "        for message in messages:\n",
    "            message_dict = message.model_dump()\n",
    "            msg_type = message_dict[\"type\"]\n",
    "            \n",
    "            if msg_type == \"ai\":\n",
    "                if tool_calls := message_dict.get(\"tool_calls\"):\n",
    "                    for tool_call in tool_calls:\n",
    "                        responses.append(\n",
    "                            self.create_function_call_item(\n",
    "                                id=message_dict.get(\"id\") or str(uuid.uuid4()),\n",
    "                                call_id=tool_call[\"id\"],\n",
    "                                name=tool_call[\"name\"],\n",
    "                                arguments=json.dumps(tool_call[\"args\"]),\n",
    "                            )\n",
    "                        )\n",
    "                else:\n",
    "                    responses.append(\n",
    "                        self.create_text_output_item(\n",
    "                            text=message_dict.get(\"content\", \"\"),\n",
    "                            id=message_dict.get(\"id\") or str(uuid.uuid4()),\n",
    "                        )\n",
    "                    )\n",
    "            elif msg_type == \"tool\":\n",
    "                responses.append(\n",
    "                    self.create_function_call_output_item(\n",
    "                        call_id=message_dict[\"tool_call_id\"],\n",
    "                        output=message_dict[\"content\"],\n",
    "                    )\n",
    "                )\n",
    "            elif msg_type == \"human\":\n",
    "                responses.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": message_dict.get(\"content\", \"\")\n",
    "                })\n",
    "        \n",
    "        return responses\n",
    "    \n",
    "    def _create_graph(self, checkpointer: PostgresSaver):\n",
    "        \"\"\"Create the LangGraph workflow\"\"\"\n",
    "        def should_continue(state: AgentState):\n",
    "            messages = state[\"messages\"]\n",
    "            last_message = messages[-1]\n",
    "            if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "                return \"continue\"\n",
    "            return \"end\"\n",
    "        \n",
    "        if self.system_prompt:\n",
    "            preprocessor = RunnableLambda(\n",
    "                lambda state: [{\"role\": \"system\", \"content\": self.system_prompt}] + state[\"messages\"]\n",
    "            )\n",
    "        else:\n",
    "            preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "        \n",
    "        model_runnable = preprocessor | self.model_with_tools\n",
    "        \n",
    "        def call_model(state: AgentState, config: RunnableConfig):\n",
    "            response = model_runnable.invoke(state, config)\n",
    "            return {\"messages\": [response]}\n",
    "        \n",
    "        workflow = StateGraph(AgentState)\n",
    "        workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "        \n",
    "        if tools:\n",
    "            workflow.add_node(\"tools\", ToolNode(tools))\n",
    "            workflow.add_conditional_edges(\n",
    "                \"agent\",\n",
    "                should_continue,\n",
    "                {\"continue\": \"tools\", \"end\": END}\n",
    "            )\n",
    "            workflow.add_edge(\"tools\", \"agent\")\n",
    "        else:\n",
    "            workflow.add_edge(\"agent\", END)\n",
    "        \n",
    "        workflow.set_entry_point(\"agent\")\n",
    "        \n",
    "        return workflow.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        \"\"\"Non-streaming prediction\"\"\"\n",
    "        # The same thread_id is used by BOTH predict() and predict_stream()\n",
    "        ci = dict(request.custom_inputs or {})\n",
    "        if \"thread_id\" not in ci:\n",
    "            ci[\"thread_id\"] = str(uuid.uuid4())\n",
    "        request.custom_inputs = ci\n",
    "\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs={\"thread_id\": ci[\"thread_id\"]})\n",
    "    \n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        \"\"\"Streaming prediction with PostgreSQL checkpointing\"\"\"\n",
    "        # Get thread ID from custom inputs or generate new one\n",
    "        thread_id = (request.custom_inputs or {}).get(\"thread_id\", str(uuid.uuid4()))\n",
    "        \n",
    "        # Convert incoming Responses messages to ChatCompletions format\n",
    "        # LangChain will automatically convert from ChatCompletions to LangChain format\n",
    "        cc_msgs = self.prep_msgs_for_cc_llm([i.model_dump() for i in request.input])\n",
    "        langchain_msgs = cc_msgs\n",
    "        \n",
    "        checkpoint_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        # Use connection from pool\n",
    "        with self.get_connection() as conn:            \n",
    "            # Create checkpointer and graph\n",
    "            checkpointer = PostgresSaver(conn)\n",
    "            graph = self._create_graph(checkpointer)\n",
    "            \n",
    "            # Stream the graph execution\n",
    "            for event in graph.stream(\n",
    "                {\"messages\": langchain_msgs},\n",
    "                checkpoint_config,\n",
    "                stream_mode=[\"updates\", \"messages\"]\n",
    "            ):\n",
    "                if event[0] == \"updates\":\n",
    "                    for node_data in event[1].values():\n",
    "                        for item in self._langchain_to_responses(node_data[\"messages\"]):\n",
    "                            yield ResponsesAgentStreamEvent(\n",
    "                                type=\"response.output_item.done\",\n",
    "                                item=item\n",
    "                            )\n",
    "                # Stream message chunks for real-time text generation\n",
    "                elif event[0] == \"messages\":\n",
    "                    try:\n",
    "                        chunk = event[1][0]\n",
    "                        if isinstance(chunk, AIMessageChunk) and chunk.content:\n",
    "                            yield ResponsesAgentStreamEvent(\n",
    "                                **self.create_text_delta(\n",
    "                                    delta=chunk.content,\n",
    "                                    item_id=chunk.id\n",
    "                                ),\n",
    "                            )\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error streaming chunk: {e}\")\n",
    "\n",
    "\n",
    "# ----- Export model -----\n",
    "AGENT = LangGraphResponsesAgent(LAKEBASE_CONFIG)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "417a76af-dbb6-4e9e-bdc3-6e80e1ad5e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the Agent locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "897d62f7-34bc-4f64-b7f2-f113bf4e5c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d543ecc8-e2a4-4b22-8c1e-ee8777f5e090",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "# Message 1, don't include thread_id (creates new thread)\n",
    "result = AGENT.predict({\n",
    "    \"input\": [{\"role\": \"user\", \"content\": \"I am working on stateful agents\"}]\n",
    "})\n",
    "print(result.model_dump(exclude_none=True))\n",
    "thread_id = result.custom_outputs[\"thread_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14980e4c-3691-4fc1-ad7b-17e8183afe67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Message 2, include thread ID and notice how agent remembers context from previous predict message\n",
    "response2 = AGENT.predict({\n",
    "    \"input\": [{\"role\": \"user\", \"content\": \"What am I working on?\"}],\n",
    "    \"custom_inputs\": {\"thread_id\": thread_id}\n",
    "})\n",
    "print(\"Response 2:\", response2.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f70689-99b1-42b4-bdcb-92c6304784a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example calling agent without passing in thread id - notice it does not retain the memory\n",
    "response3 = AGENT.predict({\n",
    "    \"input\": [{\"role\": \"user\", \"content\": \"What am I working on?\"}],\n",
    "})\n",
    "print(\"Response 3 No thread id passed:\", response3.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff0ad62-859b-4772-bc6f-f9d4cce8a080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# predict stream example\n",
    "for chunk in AGENT.predict_stream({\n",
    "    \"input\": [{\"role\": \"user\", \"content\": \"What am I working on?\"}],\n",
    "    \"custom_inputs\": {\"thread_id\": thread_id}\n",
    "}):\n",
    "    print(\"Chunk:\", chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcebb9ad-1702-485b-9b66-0c5c1e6f5a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Log the agent as an MLflow model\n",
    "Log the agent as code from the agent.py file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "## Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model()`.\n",
    "\n",
    "**TODO:** \n",
    "- Add lakebase as a resource type\n",
    "- If your Unity Catalog tool queries a [vector search index](https://docs.databricks.com/docs%20link) or leverages [external functions](https://docs.databricks.com/docs%20link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a28395e3-a434-44e3-850c-4da59df36e8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import tools, LLM_ENDPOINT_NAME, LAKEBASE_CONFIG\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksLakebase\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [DatabricksServingEndpoint(LLM_ENDPOINT_NAME), DatabricksLakebase(database_instance_name=LAKEBASE_CONFIG[\"instance_name\"])]\n",
    "\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is an LLM agent?\"\n",
    "        }\n",
    "    ],\n",
    "    \"custom_inputs\": {\"thread_id\": \"example-thread-123\"},\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            \"databricks-langchain\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "            f\"langgraph-checkpoint-postgres=={get_distribution('langgraph-checkpoint-postgres').version}\",\n",
    "            f\"psycopg[binary,pool]\",\n",
    "            f\"pydantic=={get_distribution('pydantic').version}\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b69a782f-e0b8-4e66-be7e-4dcd70f2e142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Evaluate the agent with Agent Evaluation\n",
    "Use Mosaic AI Agent Evaluation to evalaute the agent's responses based on expected responses and other evaluation criteria. Use the evaluation criteria you specify to guide iterations, using MLflow to track the computed quality metrics. See Databricks documentation ([AWS](https://docs.databricks.com/(https://docs.databricks.com/aws/generative-ai/agent-evaluation) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)).\n",
    "\n",
    "To evaluate your tool calls, add custom metrics. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/agent-evaluation/custom-metrics.html#evaluating-tool-calls) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-evaluation/custom-metrics#evaluating-tool-calls))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be48cb00-1163-4d53-8ae3-bbcca7602d60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, RetrievalGroundedness, RetrievalRelevance, Safety\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\"input\": [{\"role\": \"user\", \"content\": \"Calculate the 15th Fibonacci number\"}]},\n",
    "        \"expected_response\": \"The 15th Fibonacci number is 610.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],  # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1de25b6-0055-42ca-9efd-97d2c9c2f649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the mlflow.models.predict() API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a7e4d9c-a32c-427c-97d7-c46d6ca28904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"input\": [{\"role\": \"user\", \"content\": \"I am working on stateful agents\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3bacd37-89d4-4ae7-9582-a799f116a5a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register the model to Unity Catalog\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bff8902-06f0-4f5b-aa1e-7be2c80e744e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"catalog\"\n",
    "schema = \"schema\"\n",
    "model_name = \"stateful-agent-threads-example\"\n",
    "\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5133307e-20a2-43dc-bdae-ad28538de9dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e0a584-ff89-4142-903c-f73ed287d0f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags = {\"endpointSource\": \"docs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac0db6f-5d36-4633-bf6b-b5fdbd1ac227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Next steps\n",
    "It will take around 15 minutes for you to finish deploying your agent. After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. \n",
    "\n",
    "Now, with your stateful agent, you can pick up past threads and continue the conversation.\n",
    "\n",
    "You can query your Lakebase instance to see a record of your conversation at various threads/checkpoints. Here is a basic query to see 10 checkpoints:\n",
    "```\n",
    "-- See all conversation threads with their metadata\n",
    "SELECT \n",
    "    *\n",
    "FROM checkpoints\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "Check most recently logged checkpoints:\n",
    "```\n",
    "SELECT\n",
    "    c.*,\n",
    "    (c.checkpoint::json->>'ts')::timestamptz AS ts\n",
    "FROM checkpoints c\n",
    "ORDER BY ts DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_stateful-agent-lakebase",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
